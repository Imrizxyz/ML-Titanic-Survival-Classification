# ğŸš¢ Titanic Survival Prediction using Logistic Regression

This project predicts whether a passenger survived the Titanic disaster based on features like **class, gender, age and fare** using a **Logistic Regression Machine Learning model**.

---

## ğŸ“Š Project Overview
- Input features: `pclass`, `sex`, `age`, `fare`
- Target output: `survived` (0 = No, 1 = Yes)
- Model: **Logistic Regression**
- Dataset: Titanic dataset from Seaborn Library

---

## ğŸ§  Tech Stack
| Library / Tool | Purpose |
|----------------|----------|
| Python | Programming |
| Pandas / Numpy | Data handling |
| Seaborn | Dataset + Visualization |
| Scikit-Learn | ML model training |

---

## ğŸ“Œ Workflow (Step-by-Step)
1. Load dataset using Seaborn
2. Clean missing values (age, fare)
3. Convert categorical values (`sex`) to numeric
4. Split into Train/Test sets
5. Train Logistic Regression model
6. Predict + evaluate accuracy
7. User input-based prediction

---

## ğŸ¯ Results
- **Model Accuracy:** ~78% - 82% (depends on split)
- Example Output:

---

## ğŸš€ How to Run
1. Clone this repo  
2. Open the `.ipynb` file in **Google Colab** or **Jupyter Notebook**  
3. Run all cells in order  
4. Enter Passenger details when asked

---

## ğŸ“ˆ Model Used
- Logistic Regression
- Reason: Best for **binary classification (0/1)** problems

---

## ğŸ“ Folder Structure
ML-Titanic-Survival-Classification/
â”‚
â”œâ”€â”€ titanic_survival.ipynb # Main code & model
â””â”€â”€ README.md # Documentation


---

## ğŸ’¡ Use Cases
- Binary classification use case
- Basic healthcare / risk prediction analogy
- Customer retention (similar logic to churn prediction)

---

## ğŸ§  Learning Outcomes
- Data preprocessing & cleaning
- Handling categorical variables
- Model training & evaluation
- Python + Scikit-Learn ML pipeline

---

## ğŸ“¬ Connect
GitHub: https://github.com/Imrizxyz

---

â­ If you like this project, consider giving the repo a star!

  
